<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LeonHwang&#39;s Blogs</title>
    <link>https://asphaltt.github.io/</link>
    <description>Recent content on LeonHwang&#39;s Blogs</description>
    <generator>Hugo 0.125.0-DEV</generator>
    <language>zh</language>
    <copyright>Leon Hwang</copyright>
    <lastBuildDate>Sun, 23 Jun 2024 22:21:31 +0800</lastBuildDate>
    <atom:link href="https://asphaltt.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>eBPF Talk: 跟踪 RPS/XPS 配置变更</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-120-trace-rpsxps/</link>
      <pubDate>Sun, 23 Jun 2024 22:21:31 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-120-trace-rpsxps/</guid>
      <description>既然实现了 eBPF Talk: 跟踪 IRQ 绑核，那么也实现一下跟踪 RPS/XPS 配置变更吧。 RPS/XPS 是什么？RPS 是 Receive Packet Steering，XPS 是 Transmit Packet Steering。它们是 Linux 内核</description>
    </item>
    <item>
      <title>eBPF Talk: 跟踪 IRQ 绑核</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-119-trace-irq-binding/</link>
      <pubDate>Mon, 17 Jun 2024 00:23:36 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-119-trace-irq-binding/</guid>
      <description>在 XDP 网关项目中，为了提高网络包吞吐性能，需要充分利用 CPU 核；这就需要调整网卡 queue 数量，并将 queue 对应的 IRQ 绑定到指定的 CPU 核上。 因此，在绑核之后，需要对</description>
    </item>
    <item>
      <title>eBPF Talk: 一行代码两行泪</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-118-one-line-code-and-two-bugs/</link>
      <pubDate>Sun, 02 Jun 2024 21:42:03 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-118-one-line-code-and-two-bugs/</guid>
      <description>周一（5 月 27 日）上班在验证个功能的时候，发现功能异常了。 周一排查了一整天，心都要滴血了，都没能排查出功能异常的原因。 周二排查出原因了，是同事</description>
    </item>
    <item>
      <title>eBPF Talk: vista 支持对 XDP/tc-bpf 进行抓包</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-117-pcap-in-vista/</link>
      <pubDate>Sun, 26 May 2024 16:30:37 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-117-pcap-in-vista/</guid>
      <description>对内核 skb 进行 trace 是一种时髦，使用 eBPF 进行抓包是另一种时髦。本文介绍 vista 是如何赶另一种时髦的。 了解到 eBPF 能够实现抓包后，心痒不已，而且 vista 已支持对 XDP/tc-bpf 进行</description>
    </item>
    <item>
      <title>eBPF Talk: 混部环境下无损升级 XDP 程序的思路</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-116-upgrade-xdp-costlessly/</link>
      <pubDate>Sun, 26 May 2024 16:28:58 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-116-upgrade-xdp-costlessly/</guid>
      <description>混部环境指的是当前服务器不是 XDP 程序独占的，部署有其它的网络服务。 如果服务器使用的是 Intel 网卡、而且 XDP 程序采用 Native 模式挂载到网卡上，那么在挂载和卸载</description>
    </item>
    <item>
      <title>eBPF Talk: pwru 继承者 vista</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-115-introduce-vista/</link>
      <pubDate>Sun, 26 May 2024 16:28:14 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-115-introduce-vista/</guid>
      <description>花了点时间，将 pwru、skbtracer-iptables、 socketrace 和几个 TCP bpftrace 脚本缝合了起来，形成了一个新的工具，叫做 vista。 GitHub: vista vista 简介 1 2</description>
    </item>
    <item>
      <title>eBPF Talk: XDP dispatcher 简介</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-114-introduce-xdp-dispatcher/</link>
      <pubDate>Sun, 26 May 2024 16:27:14 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-114-introduce-xdp-dispatcher/</guid>
      <description>自 5.6 kernel bpf dispatcher 被引入到 Linux 内核中。 bpf: Introduce BPF dispatcher 到目前 6.9 kernel，仍然只有 XDP 程序在使用 bpf dispatcher。 bpf dispatcher 的引入，是为了解决间接调用叠加 retpoline 带</description>
    </item>
    <item>
      <title>eBPF Talk: XDP 进阶手册</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-113-xdp-mastery-guide/</link>
      <pubDate>Sun, 26 May 2024 16:25:19 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-113-xdp-mastery-guide/</guid>
      <description>XDP，全称为 eXpress Data Path，是 Linux 内核 4.8 版本引入的一种高性能网络数据包处理技术。 XDP 只能用来处理网卡接收到的网络包，可对网络包进行修改、丢弃、转</description>
    </item>
    <item>
      <title>eBPF Talk: 使用隔离的 netns 避免 iptables 规则干扰收发 ping 包</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-112-use-netns-to-keep-away-from-iptables/</link>
      <pubDate>Sun, 26 May 2024 16:22:03 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-112-use-netns-to-keep-away-from-iptables/</guid>
      <description>为了降本增效，网关部署到了业务的节点上，参考 eBPF Talk: 善用 TCP option 来支持网关 ping。然而，业务节点上可能会配置不少 iptables 规则，从该节点 ping 另一台网关的时候</description>
    </item>
    <item>
      <title>eBPF Talk: 善用 TCP option 来支持网关 ping</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-111-tcp-option-for-gateway-ping/</link>
      <pubDate>Sun, 26 May 2024 16:20:37 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-111-tcp-option-for-gateway-ping/</guid>
      <description>这里的网关 ping 指的是对虚拟网络网关发包，确认网关的数据面能够符合预期地转发网络包。 在部署、升级网关的时候，需要对网关进行 ping 测试，以确认网关的数</description>
    </item>
    <item>
      <title>eBPF Talk: 开放 eBPF vm on eBPF 源代码</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-110-source-code-of-ebpf-vm-on-ebpf/</link>
      <pubDate>Sun, 26 May 2024 16:17:08 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-110-source-code-of-ebpf-vm-on-ebpf/</guid>
      <description>在 eBPF Talk: 巨献 eBPF vm on eBPF 一文中，简要介绍了 eBPF vm on eBPF；经过一番考虑后，决定将 eBPF vm on eBPF 的源代码开放出来。 TL;DR 源代码：eBPF vm on eBPF。 eBPF vm 该 vm</description>
    </item>
    <item>
      <title>eBPF Talk: xdpsnoop 一个 XDP 安装过程的跟踪工具</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-109-xdpsnoop/</link>
      <pubDate>Sun, 26 May 2024 16:15:57 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-109-xdpsnoop/</guid>
      <description>想起 eBPF Talk: 达成内核 bpf 子系统贡献者成就 给内核新增了一个 XDP 安装失败的 tracepoint；现在想来，这个 tracepoint 有点鸡肋，因为可以通过 kprobe 一些函数就能解决</description>
    </item>
    <item>
      <title>eBPF Talk: 给 eCapture 支持 pcap-filter 的艰辛历程</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-108-ecapture-supports-pcap-filter/</link>
      <pubDate>Sun, 26 May 2024 16:14:02 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-108-ecapture-supports-pcap-filter/</guid>
      <description>历经千辛万苦，给 eCapture 支持的 pcap-filter PR feat: Support pcap-filter expression for pcap mode 终于合并了：eCapture v0.7.4发布，支持Pcap Filter包过滤语法。感谢 @CFC4N 大佬的认可</description>
    </item>
    <item>
      <title>eBPF Talk: 打造自己的 socket 跟踪工具 socketrace</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-107-introduce-socketrace/</link>
      <pubDate>Sun, 26 May 2024 15:53:12 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-107-introduce-socketrace/</guid>
      <description>忽而蹦出个想法：何不参考 pwru 那样，跟踪所有带有 struct sock *sk 参数的函数？ 既然脱胎于 pwru，那么就直接复用 pwru 的代码，快速实现一个 socketrace 工具。 1 2 3 4 5 6 7</description>
    </item>
    <item>
      <title>eBPF Talk: ethtool 跟踪工具 ethtoolsnoop</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-106-introduce-ethtoolsnoop/</link>
      <pubDate>Sun, 26 May 2024 15:51:23 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-106-introduce-ethtoolsnoop/</guid>
      <description>在 eBPF Talk: 记录一次网络抖动排障 中，遇到了 ethtool -m XXX 导致的网络抖动问题。因为没有趁手的工具直接排查出问题的原因，所以，我写了一个 ethtool 跟踪工具 ethtoo</description>
    </item>
    <item>
      <title>eBPF Talk: 记录一次网络抖动排障</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-105-network-jitter/</link>
      <pubDate>Sun, 26 May 2024 15:49:47 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-105-network-jitter/</guid>
      <description>最近做了一次网络抖动排障，庆幸定位到了原因，记录一下。 网络抖动的表现 业务方是 DB 团队，他们对慢查询有监控，发现了一些慢查询；而且，确认是接入虚</description>
    </item>
    <item>
      <title>eBPF Talk: `tailcall` in `bpf2bpf` 踩坑一则</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-104-tailcall-in-bpf2bpf/</link>
      <pubDate>Sun, 26 May 2024 15:47:06 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-104-tailcall-in-bpf2bpf/</guid>
      <description>在 bpf2bpf 里使用 tailcall 时，可以达到意想不到的效果： tailcall 目标 bpf prog 复用当前 subprog 的栈空间，而不是 subprog caller 的栈空间。 subprog caller 能获取到 tailcall 目标 bpf prog 的返回值。 tailcall in bpf2bpf 支持情况 从 5.10</description>
    </item>
    <item>
      <title>eBPF Talk: 巨献 eBPF vm on eBPF</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-103-ebpf-vm-on-ebpf/</link>
      <pubDate>Sun, 26 May 2024 15:42:24 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-103-ebpf-vm-on-ebpf/</guid>
      <description>花了几天时间，将 eBPF vm on eBPF 的想法实现了一下，这是一个非常有趣的想法。以前用 Go 实现过 eBPF vm，所以这回轻车熟路，很快就实现了一个 eBPF vm on eBPF demo。</description>
    </item>
    <item>
      <title>eBPF Talk: Unix Socket 抓包工具 sockdump</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-102-introduce-sockdump/</link>
      <pubDate>Sun, 26 May 2024 15:40:38 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-102-introduce-sockdump/</guid>
      <description>犹如 2 年前抄狄老师的 skbtracer 一样，当看到 sockdump 时，又抄了一回作业。原 sockdump 也是基于 bcc 的项目，我把它改造成了基于 Go+eBPF CO-RE 的项目，下载二进制文件即可立马用起来。 skbtracer</description>
    </item>
    <item>
      <title>eBPF Talk: XDP 支持 traceroute</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-101-xdp-supports-traceroute/</link>
      <pubDate>Sun, 26 May 2024 15:37:31 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-101-xdp-supports-traceroute/</guid>
      <description>不管 traceroute 具体的工作原理是什么，只需要抓住一点：如果当前的包 IP 头里的 TTL 是 1，那么就可以回一个 ICMP TtlExceeded 包，这样就可以支持 traceroute 和 mtr 了。 TL;DR XDP 程序里的处理逻辑</description>
    </item>
    <item>
      <title>eBPF Talk: 从一个 pwru issue 谈起</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-100-talk-from-a-pwru-issue/</link>
      <pubDate>Sun, 26 May 2024 15:35:08 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-100-talk-from-a-pwru-issue/</guid>
      <description>有位 pwru 的用户在 GitHub 上提了一个 issue，说 --filter-trace-tc 不能正常工作。 option &amp;ndash;filter-trace-tc not support 1 2 3 4 5 6 7 8 9 ...... ; event.addr = bpf_get_func_ip(ctx); 26: (bf) r1 = r6 27: R0=invP1 R1_w=ctx(id=0,off=0,imm=0) R6=ctx(id=0,off=0,imm=0) R7=ptr_sk_buff(id=0,off=0,imm=0) R10=fp0 fp-8=????mmmm fp-16=00000000 fp-24=00000000 fp-32=0mm0mmmm fp-40=mmmmmmmm fp-48=mmmmmmmm fp-56=mmmmmmmm fp-64=mmmmmmmm fp-72=00000000 fp-80=00000000 fp-88=00000000 fp-96=00000000 fp-104=mmmmmmmm</description>
    </item>
    <item>
      <title>eBPF Talk: tc-dump 支持 pcap-filter</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-99-tc-dump-supports-pcap-filter/</link>
      <pubDate>Wed, 15 May 2024 23:39:22 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-99-tc-dump-supports-pcap-filter/</guid>
      <description>tc-dump 是一个基于 eBPF 的 tc 抓包工具，支持抓取 tc 的 ingress 和 egress 方向的包。 最近，tc-dump 支持了 pcap-filter，即支持了 pcap 的过滤语法。 与此同时，t</description>
    </item>
    <item>
      <title>eBPF Talk: 给 pwru 添砖加瓦</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-98-contribute-pwru/</link>
      <pubDate>Wed, 15 May 2024 23:38:29 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-98-contribute-pwru/</guid>
      <description>近来，没怎么学习 eBPF，就给 pwru 做下贡献。 Replace objs with collection Support tracing tc-bpf Support tracking skb clones Accelerate attaching/detaching kprobes WIP Replace objs with collection 该 PR 重构了一下 pwru 中管理 bpf 对象的代码，将 bpf 对象的管理从 struct 改成 c</description>
    </item>
    <item>
      <title>eBPF Talk: 手撕 XDP 程序</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-97-analyse-xdp/</link>
      <pubDate>Wed, 15 May 2024 23:37:46 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-97-analyse-xdp/</guid>
      <description>前段时间，老板让我 手撕 分析 一个陌生的 XDP 程序。 责任重过山头，莫敢推辞，只能硬着头皮上了。 陌生的 XDP 程序 没有源代码，且发现该 XDP 程序还没带上 debug 信息；</description>
    </item>
    <item>
      <title>eBPF Talk: 内核 bpf 子系统贡献&#43;&#43;</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-96-kernel-bpf-contribution-/</link>
      <pubDate>Wed, 15 May 2024 23:33:01 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-96-kernel-bpf-contribution-/</guid>
      <description>最近在忙着些什么呢？没有发表 eBPF 技术文章了。 本公众号并没有被封号、也没有被禁言；其实，最近在忙着向内核 bpf 子系统贡献 patch，在不断完善 tailcall 这个</description>
    </item>
    <item>
      <title>eBPF Talk: 内核 bpf 子系统贡献之修复 tailcall 无限循环</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-95-kernel-bpf-contribution/</link>
      <pubDate>Wed, 15 May 2024 23:31:03 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-95-kernel-bpf-contribution/</guid>
      <description>梅开二度，再次向内核 bpf 子系统贡献 patch。 bpf, x64: Fix tailcall infinite loop 此次修复的是 x64 平台的一个 bug，该 bug 会导致 tailcall 陷入无限循环，最终导致宕机。 tailcall 无限循环 如</description>
    </item>
    <item>
      <title>eBPF Talk: introduce kfuncs</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-94-introduce-kfuncs/</link>
      <pubDate>Wed, 15 May 2024 23:29:42 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-94-introduce-kfuncs/</guid>
      <description>通过 bpf: Support bpf program calling kernel function 学习 kfuncs 的实现。 不过，此 kfuncs 不是 bpftrace kfunc/kretfunc: Kernel Functions Tracing。bpftrace 的 kfunc 是的底层是 fentry/fexit。 BPF Kernel Functions (kfuncs) 该内核</description>
    </item>
    <item>
      <title>eBPF Talk: tailcall in freplace 有 BUG</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-93-tailcall-in-freplace-bug/</link>
      <pubDate>Wed, 15 May 2024 23:27:52 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-93-tailcall-in-freplace-bug/</guid>
      <description>tailcall in freplace 有 BUG？真的？假的！ 最近，偶然发现在 freplace 里使用 tailcall 有 BUG。尽管，我的同事早就发现了有问题，但不确定是不是内核的问题。所以，我就花了点时</description>
    </item>
    <item>
      <title>eBPF Talk: 尝试 trace tailcall 程序？！</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-92-try-trace-tailcall/</link>
      <pubDate>Wed, 15 May 2024 23:22:40 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-92-try-trace-tailcall/</guid>
      <description>在 eBPF Talk: trace tailcall 程序？NO！ 里，我们知道 tailcall 程序是不能直接使用 fentry/fexit 进行 trace 的。 如果通过内核模块，使用比较 hack 的方式，能否 trace tailcall 程序呢？ TL;DR 能对静态 tailcall 进行 tra</description>
    </item>
    <item>
      <title>eBPF Talk: 达成内核 bpf 子系统贡献者成就</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-89-kernel-bpf-contributor/</link>
      <pubDate>Wed, 15 May 2024 23:20:40 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-89-kernel-bpf-contributor/</guid>
      <description>给 XDP 新增了一个 tracepoint；历时一个月，终不负所望。 bpf, xdp: Add tracepoint to xdp attaching failure 年份：2023 年。 需求来源 说来惭愧，需求不来自公司、也不来自我自</description>
    </item>
    <item>
      <title>eBPF Talk: introduce tracepoint</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-87-introduce-tracepoint/</link>
      <pubDate>Wed, 15 May 2024 23:15:33 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-87-introduce-tracepoint/</guid>
      <description>想弄清楚 tracepoint 的工作原理，实在太难了；网络上的资料比较少，而且不够深入，甚至是 kernel 文档。 Using the Linux Kernel Tracepoints 本文尝试从源代码的角度来分析 tracepoint 的工作原理。 抛砖引</description>
    </item>
    <item>
      <title>eBPF Talk: bpf link 简介</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-76-introduce-bpf_link/</link>
      <pubDate>Sun, 12 May 2024 20:11:06 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-76-introduce-bpf_link/</guid>
      <description>bpf link 的引入是为了解决 bpf prog attachment 持久化的问题，并由此引入了 bpf link fd。 bpf: Introduce pinnable bpf_link abstraction since kernel 5.7 在引入了 bpf link 之后，常用的 bpf prog attachment 都实现了对应的 bpf link，比如 TRACING,</description>
    </item>
    <item>
      <title>eBPF Talk: tracepoint __data_loc</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-86-tracepoint-__data_loc/</link>
      <pubDate>Fri, 05 Apr 2024 22:45:28 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-86-tracepoint-__data_loc/</guid>
      <description>书接上回：eBPF Talk: trace tracepoint 程序，本文将介绍在 bpf 里如何处理 tracepoint 中 __data_loc 描述的字段。 关于 tracepoint __data_loc 的资料超级少，网络上能找到的资料如下： tracepoint arguments are missing __data_loc char strings tracepoint: Support __data_loc fields</description>
    </item>
    <item>
      <title>eBPF Talk: trace tracepoint 程序</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-85-trace-tracepoint-program/</link>
      <pubDate>Thu, 04 Apr 2024 22:38:55 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-85-trace-tracepoint-program/</guid>
      <description>此处指的是 trace tracepoint bpf 程序，而不是 trace tracepoint 事件。 eBPF Talk: trace XDP 程序 eBPF Talk: trace tc-bpf 程序 eBPF Talk: trace bpf2bpf 函数调用 eBPF Talk: trace freplace 程序 eBPF Talk: trace tailcall 程序？NO！ eBPF Talk: trace kprobe 程序 eBPF Talk: trace tracepoint 程序 trace tracepoint 程</description>
    </item>
    <item>
      <title>eBPF Talk: trace kprobe 程序</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-84-trace-kprobe-program/</link>
      <pubDate>Thu, 04 Apr 2024 22:37:42 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-84-trace-kprobe-program/</guid>
      <description>此处指的是 trace kprobe bpf 程序，而不是 trace kprobe 事件。 eBPF Talk: trace XDP 程序 eBPF Talk: trace tc-bpf 程序 eBPF Talk: trace bpf2bpf 函数调用 eBPF Talk: trace freplace 程序 eBPF Talk: trace tailcall 程序？NO！ eBPF Talk: trace kprobe 程序 eBPF Talk: trace tracepoint 程序 trace kprobe 程</description>
    </item>
    <item>
      <title>eBPF Talk: trace tailcall 程序？NO！</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-83-trace-tailcall-program/</link>
      <pubDate>Thu, 04 Apr 2024 22:34:32 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-83-trace-tailcall-program/</guid>
      <description>既然可以对 freplace 程序进行 trace，是否可以对 tailcall 程序进行 trace 呢？ eBPF Talk: trace XDP 程序 eBPF Talk: trace tc-bpf 程序 eBPF Talk: trace bpf2bpf 函数调用 eBPF Talk: trace freplace 程序 eBPF Talk: trace tailcall 程序？NO！ eBPF Talk: trace kprobe 程</description>
    </item>
    <item>
      <title>eBPF Talk: trace freplace 程序</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-82-trace-freplace-program/</link>
      <pubDate>Thu, 04 Apr 2024 22:30:23 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-82-trace-freplace-program/</guid>
      <description>既然可以对 bpf2bpf 函数调用进行 trace，是否可以对 freplace 程序进行 trace 呢？ eBPF Talk: trace XDP 程序 eBPF Talk: trace tc-bpf 程序 eBPF Talk: trace bpf2bpf 函数调用 eBPF Talk: trace freplace 程序 eBPF Talk: trace tailcall 程序？NO！ eBPF Talk: trace</description>
    </item>
    <item>
      <title>eBPF Talk: trace bpf2bpf 函数调用</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-81-trace-bpf2bpf-program/</link>
      <pubDate>Thu, 04 Apr 2024 22:28:58 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-81-trace-bpf2bpf-program/</guid>
      <description>如 trace XDP/tc-bpf 程序，bpf2bpf 函数调用也是可以被 trace 的。 eBPF Talk: trace XDP 程序 eBPF Talk: trace tc-bpf 程序 eBPF Talk: trace bpf2bpf 函数调用 eBPF Talk: trace freplace 程序 eBPF Talk: trace tailcall 程序？NO！ eBPF Talk: trace kprobe 程序 eBPF Talk: trace</description>
    </item>
    <item>
      <title>eBPF Talk: trace tc-bpf 程序</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-80-trace-tc-bpf-program/</link>
      <pubDate>Thu, 04 Apr 2024 22:18:37 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-80-trace-tc-bpf-program/</guid>
      <description>如 eBPF Talk: trace XDP 程序，使用 bpf 也是能够对 tc-bpf 程序进行 trace 的。 eBPF Talk: trace XDP 程序 eBPF Talk: trace tc-bpf 程序 eBPF Talk: trace bpf2bpf 函数调用 eBPF Talk: trace freplace 程序 eBPF Talk: trace tailcall 程序？NO！ eBPF Talk: trace kprobe 程序 eBPF Talk: trace tracepoint</description>
    </item>
    <item>
      <title>eBPF Talk: trace XDP 程序</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-79-trace-xdp-program/</link>
      <pubDate>Thu, 04 Apr 2024 21:59:50 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-79-trace-xdp-program/</guid>
      <description>在 XDP 程序运行起来后，特别是在生产环境中，有没有办法去观察它的运行情况呢？特别是 XDP 程序的最终结果。 将问题泛化一下，即有没有办法去 trace bpf 程序？ TL;DR 有</description>
    </item>
    <item>
      <title>eBPF Talk: XDP ACL 进阶之 TupleMerge</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-78-xdp-acl-tuplemerge-algo/</link>
      <pubDate>Wed, 03 Apr 2024 23:20:00 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-78-xdp-acl-tuplemerge-algo/</guid>
      <description>最近学习了网络包在线分类算法 TupleMerge，惊讶于其高效的查询和更新效率，比基于 bitmap 的算法更加节省内存、查询效率更高。本文将介绍 TupleMerge 算法的</description>
    </item>
    <item>
      <title>eBPF Talk: Ubuntu 23.04</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-77-ubuntu-23.04/</link>
      <pubDate>Wed, 03 Apr 2024 23:18:57 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-77-ubuntu-23.04/</guid>
      <description>Ubuntu 23.04 已在 4 月 20 日发布，可以到官网下载镜像安装到虚拟机，用来学习 eBPF。 Ubuntu 23.04 (Lunar Lobster) 使用的内核版本是 6.2.0-20-generic。 Ubuntu 23.04 的相关</description>
    </item>
    <item>
      <title>eBPF Talk: introduce bpf_timer</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-75-introduce-bpf_timer/</link>
      <pubDate>Wed, 03 Apr 2024 23:17:12 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-75-introduce-bpf_timer/</guid>
      <description>bpf_timer 是 eBPF 里基于 hrtimer 实现的定时器。 hrtimers - subsystem for high-resolution kernel timers LWN bpf: Introduce BPF timers. bpf: Introduce bpf timers. since 5.15 kernel bpf_timer 最初的需求是在 perf events bpf prog 中做定期采样；后来在 XDP 中可以用来做垃圾回收和健康检</description>
    </item>
    <item>
      <title>eBPF Talk: introduce bpf_iter</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-74-introduce-bpf_iter/</link>
      <pubDate>Wed, 03 Apr 2024 23:14:50 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-74-introduce-bpf_iter/</guid>
      <description>通过 Linux 网络: sequence file 的学习，我们知道在 Linux 里有不少地方都使用 sequence file 机制向用户态空间传递数据。 在 eBPF 的加持下，sequence file 机制迎来了更加灵活的实现</description>
    </item>
    <item>
      <title>Linux 网络: netdevsim</title>
      <link>https://asphaltt.github.io/post/linux-networking-5-netdevsim/</link>
      <pubDate>Wed, 03 Apr 2024 23:13:16 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-networking-5-netdevsim/</guid>
      <description>netdevsim，Netwoking Device Simulator，网络设备模拟器。 GitHub netdevsim netdevsim 就是用来模拟网络设备的，其实它是 Linux 里的一种网络设备驱动；可</description>
    </item>
    <item>
      <title>Linux 网络: sequence file</title>
      <link>https://asphaltt.github.io/post/linux-networking-4-sequence-files/</link>
      <pubDate>Wed, 03 Apr 2024 23:10:22 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-networking-4-sequence-files/</guid>
      <description>使用 ss、netstat 等命令查看 TCP 连接信息时，它们可能会从文件 /proc/net/tcp 读取 tcp socket 信息。 1 2 3 4 $ strace netstat -4 -t ... open(&amp;#34;/proc/net/tcp&amp;#34;, O_RDONLY) = 3 ... 而使用 file 命令查看 /proc/net/tcp 文件时，提示</description>
    </item>
    <item>
      <title>eBPF Talk: verifier 支持有限循环</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-73-verifier-finite-loop/</link>
      <pubDate>Wed, 03 Apr 2024 23:06:44 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-73-verifier-finite-loop/</guid>
      <description>verifier 支持有限循环后，我们不再需要 #pragma unroll 将 for 循环展开了，留给 clang 编译器决定即可。 bpf: introduce bounded loops since 5.3 kernel. 也就是，eBPF Talk: binary search 里的 __should_delay_sip() 函数里不再需要 #pragma clang loop unroll(full) 了。</description>
    </item>
    <item>
      <title>eBPF Talk: challenge verifier</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-72-challenge-verifier/</link>
      <pubDate>Wed, 03 Apr 2024 23:04:08 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-72-challenge-verifier/</guid>
      <description>在 eBPF Talk: binary search 中，我们使用一个朴素的 for 循环实现了一个二分查找的 eBPF 程序，但是，这个程序通不过 verifier，报错 &amp;ldquo;R3 unbounded memory access, make sure to bounds check any such acces</description>
    </item>
    <item>
      <title>eBPF Talk: binary search</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-71-binary-search/</link>
      <pubDate>Wed, 03 Apr 2024 23:00:58 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-71-binary-search/</guid>
      <description>其实，bpf 子系统里并没有一个叫 bpf_binary_search() 的 helper 函数。 但并不是说，在 eBPF 里就实现不了二分查找了。 小需求 怎么判断一个 IP 地址是否在某几个 CIDR 里？ 已知方法有二：</description>
    </item>
    <item>
      <title>eBPF Talk: bpf prog stats</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-70-bpf-prog-stats/</link>
      <pubDate>Wed, 03 Apr 2024 22:57:57 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-70-bpf-prog-stats/</guid>
      <description>根据以下两个 commit，可以看到，自 5.1 内核起，bpf prog 可以统计自己的运行情况了。 bpf: enable program stats 5.1 kernel. bpf: Sharing bpf runtime stats with BPF_ENABLE_STATS 5.8 kernel. bpf: Improve program stats run-time calculation 6.x kernel. stats 例子 以 bpf2bpf demo</description>
    </item>
    <item>
      <title>eBPF Talk: packet range check</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-69-packet-range-check/</link>
      <pubDate>Wed, 03 Apr 2024 22:56:16 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-69-packet-range-check/</guid>
      <description>在 XDP 或者 tc-bpf 中，经常要直接访问网络包内容；而在访问网络包内容之前，总是需要先检查访问的内容是否在 data_end 之内。 So，学习一下 packet range check 相关 commit 的历史；以史</description>
    </item>
    <item>
      <title>eBPF Talk: 踩坑 XDP on Mellanox</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-68-xdp-shit-on-mellanox/</link>
      <pubDate>Wed, 03 Apr 2024 22:54:12 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-68-xdp-shit-on-mellanox/</guid>
      <description>对 XDP 了解得越多，对 XDP 的信心越是膨胀。最近在 XDP on Mellanox 上踩了个坑，让我对 XDP 的认识又有了新的提升：就是需要保持对技术的敬畏之心，不要过于自信。 P.S. Mellanox 网</description>
    </item>
    <item>
      <title>eBPF Talk: tc-bpf 转发网络包</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-67-redirect-pkt-with-tc-bpf/</link>
      <pubDate>Wed, 03 Apr 2024 22:50:26 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-67-redirect-pkt-with-tc-bpf/</guid>
      <description>在 tc-bpf 里转发网络包，跟 XDP 里转发网络包有什么不同呢？ eBPF Talk: XDP 转发失败了 eBPF Talk: 揭秘 XDP 转发网络包 eBPF Talk: 揭秘 XDP 转发网络包【续】 呃，其实还是那个奇葩的需求，不</description>
    </item>
    <item>
      <title>eBPF Talk: eBPF 程序模块化与单测构想</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-66-an-idea-about-bpf-prog-modules-and-their-unittests/</link>
      <pubDate>Wed, 03 Apr 2024 22:48:15 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-66-an-idea-about-bpf-prog-modules-and-their-unittests/</guid>
      <description>我们来复习一下以下两篇文章： eBPF Talk: freplace on x86【汇编慎入】 eBPF Talk: 给 XDP 程序写 unittest 一个构想：使用 replace 实现 eBPF 程序的模块化，使用 BPF_PROG_TEST_RUN 对 eBPF 程序模块进行单测。 eBPF 程序</description>
    </item>
    <item>
      <title>eBPF Talk: 给 XDP 程序写 unittest</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-65-write-unittest-for-xdp/</link>
      <pubDate>Wed, 03 Apr 2024 22:46:00 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-65-write-unittest-for-xdp/</guid>
      <description>我们都知道写 unittest 是非常必要的，但是在 eBPF 程序里，该如何给 XDP 程序写 unittest 呢？ bpf: introduce BPF_PROG_TEST_RUN command since 4.12 kernel 在 4.12 内核中，引入了 BPF_PROG_TEST_RUN 命令，可以用来给 XDP 和 tc-bpf 等 eBPF 程序写 unit</description>
    </item>
    <item>
      <title>eBPF Talk: 使用 metadata 将信息从 XDP 传给 AF_XDP</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-64-metadata-from-xdp-to-af_xdp/</link>
      <pubDate>Wed, 03 Apr 2024 22:44:30 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-64-metadata-from-xdp-to-af_xdp/</guid>
      <description>学习了 XDP metadata 和 AF_XDP，是否可以使用 metadata 将信息从 XDP 传给 AF_XDP 呢？ eBPF Talk: XDP metadata 实战指南 eBPF Talk: 使用 AF_XDP 注入延时 TL;DR 答案是可以的，复制网络包内容时将 metadata 一起进行复</description>
    </item>
    <item>
      <title>eBPF Talk: helpers for bpf map</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-63-helpers-for-bpf-map/</link>
      <pubDate>Wed, 03 Apr 2024 22:40:29 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-63-helpers-for-bpf-map/</guid>
      <description>通过学习 eBPF Talk: eBPF helpers 的另一面，我们知道 eBPF helpers 是通过 bpf_func_proto 结构体来实现的，不同的 helpers 函数对应不同的 bpf_func_proto；甚至，对于同一个 helpers 函数，不</description>
    </item>
    <item>
      <title>eBPF Talk: 3.18 kernel 里的 verifier 核心内容</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-62-verifier-core-in-3.18-kernel/</link>
      <pubDate>Mon, 01 Apr 2024 23:30:37 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-62-verifier-core-in-3.18-kernel/</guid>
      <description>在 eBPF Talk: 3.18 kernel 里的 CFG 检查 里，我们学习了如何检查 bpf prog 的控制流程图（CFG，Control Flow Graph）是不是一个有向无环图（DAG，Directe</description>
    </item>
    <item>
      <title>eBPF Talk: 3.18 kernel 里的 CFG 检查</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-61-cfg-check-in-3.18-kernel/</link>
      <pubDate>Mon, 01 Apr 2024 23:28:13 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-61-cfg-check-in-3.18-kernel/</guid>
      <description>为了克服对 bpf verifier 的恐惧，打算从 verifier.c 最初的 commit 开始学习 verifier；这是因为最初版本的 verifier 并不复杂。相对而言，理解起来会容易一些。 bpf: verifier (add branch/goto checks) 在该 commit</description>
    </item>
    <item>
      <title>eBPF Talk: spinlock 详解</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-60-introduce-spinlock/</link>
      <pubDate>Mon, 01 Apr 2024 22:49:57 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-60-introduce-spinlock/</guid>
      <description>此 spinlock 指的是 eBPF 代码里使用的 struct bpf_spin_lock。 bpf: introduce bpf_spin_lock since kernel 5.1 从 eBPF Talk: 正确地进行统计 里学习到可以使用 spinlock 对统计进行保护。 spinlock 的用法就是那么简单</description>
    </item>
    <item>
      <title>eBPF Talk: 正确地进行统计</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-59-stats-bpf-prog-correctly/</link>
      <pubDate>Mon, 01 Apr 2024 22:49:01 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-59-stats-bpf-prog-correctly/</guid>
      <description>在 bpf prog 里进行统计，该怎么做呢？ PERCPU bpf map 在 bpf prog 里使用 PERCPU bpf map 进行统计，在用户态应用程序里就可以读取该 bpf map 获取从而能够计算出最终的统计数据。 使用 PERCPU bpf</description>
    </item>
    <item>
      <title>eBPF Talk: 不吐不快之 XDP ACL</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-58-complain-xdp-acl/</link>
      <pubDate>Mon, 01 Apr 2024 22:46:20 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-58-complain-xdp-acl/</guid>
      <description>之前，在学习高性能 XDP ACL 的时候，挺开心的，一下子就掌握了前沿技术。 eBPF Talk: 优化 xdp_acl eBPF Talk: 再论高性能 eBPF ACL demo for 「eBPF 技术实践：高性能 ACL」 不过在项目</description>
    </item>
    <item>
      <title>eBPF Talk: kprobe.multi 与 fprobe</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-57-kprobe.multi-and-fprobe/</link>
      <pubDate>Mon, 01 Apr 2024 21:14:35 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-57-kprobe.multi-and-fprobe/</guid>
      <description>在『eBPF Talk 读者群』里讨论起 kfuncs、kprobe、fentry/fexit 等，聊到 kprobe.multi 与 fprobe；我立刻学习了一下 kprobe.multi 和 fprobe</description>
    </item>
    <item>
      <title>eBPF Talk: 使用 AF_XDP 注入延时</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-56-latency-injection-with-af_xdp/</link>
      <pubDate>Sun, 31 Mar 2024 23:50:45 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-56-latency-injection-with-af_xdp/</guid>
      <description>学习了 AF_XDP 后，一时手痒弄了个 ping-latency-injector。 eBPF Talk: 使用 AF_XDP 加速网络【译】 eBPF Talk: XDP redirect to AF_XDP ping-latency-injector 它可以用来混淆使用 ping 实现的网络距</description>
    </item>
    <item>
      <title>eBPF Talk: XDP on veth</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-55-xdp-on-veth/</link>
      <pubDate>Sun, 31 Mar 2024 23:47:39 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-55-xdp-on-veth/</guid>
      <description>veth 是一种虚拟网络设备，并支持在驱动里运行 XDP 程序。 eBPF Talk: XDP on Mellanox 与 Mellanox 物理网卡对比，veth 上运行 XDP 程序有和区别呢？ ndo_xdp on veth 这是将 XDP 程序下发到 veth 驱动里</description>
    </item>
    <item>
      <title>eBPF Talk: XDP on Mellanox</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-54-xdp-on-mellanox/</link>
      <pubDate>Sun, 31 Mar 2024 21:22:06 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-54-xdp-on-mellanox/</guid>
      <description>为了更高的性能，需要将 XDP 程序下沉到网卡驱动里去运行。 因为服务器使用的物理网卡是 Mellanox，所以就研究一下 Mellanox 驱动里是怎么运行 XDP 程序的。 XDP</description>
    </item>
    <item>
      <title>eBPF Talk: 大佬教我 dup bpf-FD</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-53-dup-bpf-fd/</link>
      <pubDate>Sun, 31 Mar 2024 21:17:16 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-53-dup-bpf-fd/</guid>
      <description>上个星期在做 eBPF Talk: 实战经验之 bpf FD 泄漏分析 的时候，发现 GitHub cilium/ebpf 库不支持从 FD 获取 bpf link 的信息。于是，我提了个 Issue 来讨论这事： Issue link: get info from FD Issue：get</description>
    </item>
    <item>
      <title>eBPF Talk: pwru 自己挖坑自己填</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-52-eat-dog-food-of-pwru/</link>
      <pubDate>Sun, 31 Mar 2024 21:16:34 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-52-eat-dog-food-of-pwru/</guid>
      <description>当遇上 cilium/pwru 时，我便放弃维护自己的 skbtracer 了。 挖坑 之前，学习了 eBPF Talk: 全局变量实战指南，就打算在开源项目 GitHub cilium/pwru 上一展身手： PR bpf: make config as a constant 2023 年 2 月 4 日提了 PR</description>
    </item>
    <item>
      <title>eBPF Talk: 实战经验之 bpf FD 泄漏分析</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-51-bpf-fd-leak/</link>
      <pubDate>Sun, 31 Mar 2024 21:05:34 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-51-bpf-fd-leak/</guid>
      <description>不经意间，基于 XDP 的网关已写了 1w 行 Go 代码；特别是其中 ACL 模块较为复杂。 因而，担心因复杂性而带来的一些资源管理隐患，特别是不好管理的 FD 资源，专门打</description>
    </item>
    <item>
      <title>eBPF Talk: iptables-trace</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-50-iptables-trace/</link>
      <pubDate>Sun, 31 Mar 2024 21:05:00 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-50-iptables-trace/</guid>
      <description>填坑 eBPF Talk: skbtracer-iptables 中的 One more thing. 源代码：GitHub iptables-trace 前置知识： eBPF Talk: skbtracer-iptables eBPF Talk: 在内核模块里运行 bpf 程序 kprobes in kernel module 因为 eBPF 不支持修改 skb-&amp;gt;nf_trace 字段和 struct pt_regs（出于安</description>
    </item>
    <item>
      <title>eBPF Talk: 在内核模块里运行 bpf 程序</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-49-run-bpf-prog-in-kernel-module/</link>
      <pubDate>Sun, 31 Mar 2024 20:47:45 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-49-run-bpf-prog-in-kernel-module/</guid>
      <description>在 Linux 内核模块里把玩 bpf map P.S. 旧文一篇，请笑纳。 参考 iptables-bpf 的源代码实现，尝试在自定义的内核模块里运行指定的 bpf 程序。 使用的 bpf 程序源代码： iptables-bpf 内核模块源代码</description>
    </item>
    <item>
      <title>eBPF Talk: kprobe 获取第 n 个参数</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-48-kprobe-nth-argument/</link>
      <pubDate>Fri, 29 Mar 2024 23:56:03 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-48-kprobe-nth-argument/</guid>
      <description>此次来填 eBPF Talk: skbtracer-iptables 中的坑了：在开发一个基于 eBPF 的 iptables TRACE 的替代工具。 不过，遇到的第一个纸老虎是 kprobe 中获取 nf_log_trace() 的诸多参数。 nf_log_trace() 且看下函数声明： 1 2 3 4 5 6 7 8</description>
    </item>
    <item>
      <title>eBPF Talk: syscalldist 与 bpfsyscalldist</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-47-syscalldist-and-bpfsyscalldist/</link>
      <pubDate>Fri, 29 Mar 2024 23:55:06 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-47-syscalldist-and-bpfsyscalldist/</guid>
      <description>因为 XDP ACL 需要不断操作数据面的 XDP，担心 Go 代码逻辑会导致一些性能问题，所以参考 syscalldist 开发了一个专门针对 BPF 系统调用的 bpfsyscalldist。</description>
    </item>
    <item>
      <title>eBPF Talk: kprobe, frace 与 trampoline</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-46-kprobe-ftrace-and-trampoline/</link>
      <pubDate>Fri, 29 Mar 2024 23:51:43 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-46-kprobe-ftrace-and-trampoline/</guid>
      <description>听闻 ftrace 也是基于 trampoline 实现的。而且，最近打算使用 kprobe 开发个工具，所以就将快速翻看了一下 ftrace 和 kprobe 的底层源代码。 P.S. 不介绍 ftrace 的使用，使用文档请看 ftrace - Function Tra</description>
    </item>
    <item>
      <title>eBPF Talk: skbtracer-iptables</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-45-skbtracer-iptables/</link>
      <pubDate>Fri, 29 Mar 2024 23:46:26 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-45-skbtracer-iptables/</guid>
      <description>可还曾记得 skbtracer 内核网络包跟踪工具？ skbtracer: Linux 内核网络包路径追踪利器，Go 语言版本 这是我刚学习 eBPF 不久就开发的工具，不过更多时候是向 skbtracer 和 pwru 这两个网络包跟</description>
    </item>
    <item>
      <title>eBPF Talk: 共享的 tailcall PROG_ARRAY bpf map</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-88-tailcall-shared-bpf-map/</link>
      <pubDate>Tue, 22 Aug 2023 22:27:28 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-88-tailcall-shared-bpf-map/</guid>
      <description>在研究 eBPF Talk: trace tailcall 程序？NO！ 时，产生了疑惑： 静态 tailcall 使用的 PROG_ARRAY bpf map 能在多个进程之间共享吗？ TL;DR 能。且在更新 PROG_ARRAY bpf map 时，会更新静态 tailcall 的所有 bpf prog。 eBPF</description>
    </item>
    <item>
      <title>eBPF Talk: 更新 tailcall PROG_ARRAY bpf map</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-91-update-tailcall-bpf-map/</link>
      <pubDate>Tue, 22 Aug 2023 22:27:23 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-91-update-tailcall-bpf-map/</guid>
      <description>在上一集 eBPF Talk: 动态或静态 tailcall 中，我们知道了 tailcall 有动态和静态之分。 对于动态 tailcall 而言，更新 PROG_ARRAY bpf map 时就比较简单，只需要更新一下 array-&amp;gt;ptrs 数组即可。 但对于静态 tailcall 而言</description>
    </item>
    <item>
      <title>eBPF Talk: 动态或静态 tailcall</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-90-dynamic-or-static-tailcall/</link>
      <pubDate>Tue, 22 Aug 2023 22:27:18 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-90-dynamic-or-static-tailcall/</guid>
      <description>动态 tailcall？静态 tailcall？为什么 tailcall 会有动静之分呢？ 其实，就是看在使用 bpf_taill_call() 时，传入的 index 参数是常量还是变量。 动态 tailcall 在使用 bpf_tail_call() 时，传</description>
    </item>
    <item>
      <title>eBPF Talk: trampoline stack on x86【汇编慎入】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-44-trampoline-stack-on-x86/</link>
      <pubDate>Tue, 23 May 2023 23:02:47 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-44-trampoline-stack-on-x86/</guid>
      <description>本系列是 x86 架构平台上 trampoline 的实现，从原理和实现上进行了详细的介绍。 eBPF Talk: poke on x86【汇编慎入】 eBPF Talk: perilogue on x86【汇编慎入】 eBPF Talk: freplace on x86【汇编慎入】</description>
    </item>
    <item>
      <title>eBPF Talk: trampoline on x86【续】【汇编慎入】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-43-trampoline-on-x86/</link>
      <pubDate>Tue, 23 May 2023 22:55:23 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-43-trampoline-on-x86/</guid>
      <description>本系列是 x86 架构平台上 trampoline 的实现，从原理和实现上进行了详细的介绍。 eBPF Talk: poke on x86【汇编慎入】 eBPF Talk: perilogue on x86【汇编慎入】 eBPF Talk: freplace on x86【汇编慎入】</description>
    </item>
    <item>
      <title>eBPF Talk: trampoline on x86【汇编慎入】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-42-trampoline-on-x86/</link>
      <pubDate>Tue, 23 May 2023 22:45:15 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-42-trampoline-on-x86/</guid>
      <description>本系列是 x86 架构平台上 trampoline 的实现，从原理和实现上进行了详细的介绍。 eBPF Talk: poke on x86【汇编慎入】 eBPF Talk: perilogue on x86【汇编慎入】 eBPF Talk: freplace on x86【汇编慎入】</description>
    </item>
    <item>
      <title>eBPF Talk: freplace on x86【汇编慎入】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-41-freplace-on-x86/</link>
      <pubDate>Tue, 23 May 2023 22:31:24 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-41-freplace-on-x86/</guid>
      <description>本系列是 x86 架构平台上 trampoline 的实现，从原理和实现上进行了详细的介绍。 eBPF Talk: poke on x86【汇编慎入】 eBPF Talk: perilogue on x86【汇编慎入】 eBPF Talk: freplace on x86【汇编慎入】</description>
    </item>
    <item>
      <title>eBPF Talk: perilogue on x86【汇编慎入】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-40-perilogue-on-x86/</link>
      <pubDate>Tue, 23 May 2023 22:25:35 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-40-perilogue-on-x86/</guid>
      <description>本系列是 x86 架构平台上 trampoline 的实现，从原理和实现上进行了详细的介绍。 eBPF Talk: poke on x86【汇编慎入】 eBPF Talk: perilogue on x86【汇编慎入】 eBPF Talk: freplace on x86【汇编慎入】</description>
    </item>
    <item>
      <title>eBPF Talk: poke on x86【汇编慎入】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-39-poke-on-x86/</link>
      <pubDate>Tue, 23 May 2023 22:22:24 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-39-poke-on-x86/</guid>
      <description>本系列是 x86 架构平台上 trampoline 的实现，从原理和实现上进行了详细的介绍。 eBPF Talk: poke on x86【汇编慎入】 eBPF Talk: perilogue on x86【汇编慎入】 eBPF Talk: freplace on x86【汇编慎入】</description>
    </item>
    <item>
      <title>eBPF Talk: 学习经验之确认 kernel version</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-38-kernel-version/</link>
      <pubDate>Tue, 23 May 2023 22:18:00 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-38-kernel-version/</guid>
      <description>当我们想要在项目特定版本内核中落地某个 eBPF 特性时，需要确认该版本内核是否支持该 eBPF 特性。 与此同时，也想知道，该 eBPF 特性最低要求哪个版本的内核。 前置</description>
    </item>
    <item>
      <title>eBPF Talk: 实战经验之 loop</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-37-loop/</link>
      <pubDate>Tue, 23 May 2023 22:14:15 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-37-loop/</guid>
      <description>最近刚好打算使用 for 遍历 CIDR 数组的方式替换性能较差的 LPM trie bpf map，就顺便总结一下 loop 相关经验。 在 eBPF 中，出于性能、安全考虑，并不支持无限循环。这并不</description>
    </item>
    <item>
      <title>eBPF Talk: XDP redirect to AF_XDP</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-36-xdp-redirect-to-af_xdp/</link>
      <pubDate>Tue, 23 May 2023 22:09:09 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-36-xdp-redirect-to-af_xdp/</guid>
      <description>通过学习 eBPF Talk: AF_XDP，我们掌握了 AF_XDP 的那些基础知识。 提问：对于如下高性能场景，在网卡收到网络包后，该网络包会被哪个 AF_XDP socket 处理呢？ 该网卡独占一</description>
    </item>
    <item>
      <title>eBPF Talk: bpf2bpf &amp; tailcall 报错分析</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-35-bpf2bpf-and-tailcall-error/</link>
      <pubDate>Tue, 23 May 2023 22:06:44 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-35-bpf2bpf-and-tailcall-error/</guid>
      <description>终于要将 bpf2bpf &amp;amp; tailcall 的组合落地到项目中了。 不过，当头一棒的是：tail_calls are not allowed when call stack of previous frames is 256 bytes. Too large。 幸好学习过 eBPF Talk: tailcall on x86，</description>
    </item>
    <item>
      <title>eBPF Talk: 使用 AF_XDP 加速网络【译】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-34-af_xdp/</link>
      <pubDate>Tue, 23 May 2023 22:02:31 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-34-af_xdp/</guid>
      <description>本文翻译自 2018 年的 LWN: Accelerating networking with AF_XDP。 以下为译文。 Linux 网络栈不缺乏特性，且对于大部分使用场景都有不错的性能表现。不过，随着网络的高速发展，对网</description>
    </item>
    <item>
      <title>eBPF Talk: tailcall on x86【汇编慎入】【译】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-33-tailcall-on-x86/</link>
      <pubDate>Tue, 23 May 2023 21:48:41 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-33-tailcall-on-x86/</guid>
      <description>本文翻译自 Assembly within! BPF tail calls on x86 and ARM，翻译了其中 tailcall 与 x86 部分，略过 arm 部分。 eBPF Talk: tailcall 与 bpf2bpf【译】 以下为译文。 最初我们学习编程的时候，我们就学</description>
    </item>
    <item>
      <title>eBPF Talk: tailcall 与 bpf2bpf【译】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-32-tailcall-and-bpf2bpf/</link>
      <pubDate>Tue, 23 May 2023 21:44:17 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-32-tailcall-and-bpf2bpf/</guid>
      <description>本文翻译自 Cilium 出品的 BPF and XDP Reference Guide，翻译了其中的 tailcall 和 bpf2bpf 部分。 tailcall：尾调用。 bpf2bpf：BPF 到 BPF 函数调用。 tailcall tailcall 可以看作允许</description>
    </item>
    <item>
      <title>eBPF Talk: 全局变量、常量与 bpf map</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-31-global-variable-constant-variable-and-bpf-map/</link>
      <pubDate>Sun, 21 May 2023 23:38:54 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-31-global-variable-constant-variable-and-bpf-map/</guid>
      <description>全局变量的用法请参考 eBPF Talk: 全局变量实战指南。 常量的使用例子请参考 为 eBPF 程序注入黑魔法。 有同事提了个问题：在 eBPF 运行的时候是怎么访问它们的内存的呢？</description>
    </item>
    <item>
      <title>eBPF Talk: veth, XDP, GRO ?</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-30-veth-xdp-gro/</link>
      <pubDate>Sun, 21 May 2023 23:33:35 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-30-veth-xdp-gro/</guid>
      <description>书接上回 eBPF Talk: XDP 转发失败了，今回讲解为什么从物理网卡的驱动模式 XDP 程序 xdp_redirect() 到 veth 设备时一定要开启对端设备的 GRO 功能？ 网络包 xdp_redirect() 转发到哪里去？ 简单而言，网</description>
    </item>
    <item>
      <title>eBPF Talk: XDP 转发失败了</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-29-failed-to-xdp-redirect/</link>
      <pubDate>Sun, 21 May 2023 23:29:32 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-29-failed-to-xdp-redirect/</guid>
      <description>奇葩场景遇到个奇葩问题。 为了更好的性能，就将 XDP 程序挂载到网卡驱动里。但有个业务需求，在 XDP 程序里将需要延迟的流量转发到 veth 设备。所以，就直接在 XDP</description>
    </item>
    <item>
      <title>eBPF Talk: 在 veth 上运行 XDP</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-28-xdp-on-veth/</link>
      <pubDate>Sun, 21 May 2023 16:41:37 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-28-xdp-on-veth/</guid>
      <description>veth 设备在 Linux 容器网络里被广泛使用，像其它网络设备一样都支持运行 XDP 程序。 与此同时，veth 设备还支持 driver 模式的 XDP 程序。 如果在往 veth 设备上挂载 XDP 程序时</description>
    </item>
    <item>
      <title>eBPF Talk: XDP metadata 实战指南</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-27-xdp-metadata-in-action/</link>
      <pubDate>Sun, 21 May 2023 16:34:35 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-27-xdp-metadata-in-action/</guid>
      <description>最近需要在两个 XDP 程序之间传递一个最简单的信息，原本想着使用使用一个 bpf map 来传递。经过同事提醒，有 XDP metadata 可以用来传递简单信息，我便解锁了 XDP metadata 技术。</description>
    </item>
    <item>
      <title>eBPF Talk: 低性能 eBPF ACL</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-26-iptables-in-bpf/</link>
      <pubDate>Sun, 21 May 2023 16:24:22 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-26-iptables-in-bpf/</guid>
      <description>eBPF Talk: 再论高性能 eBPF ACL 中的 ACL 规则匹配算法比较复杂，晦涩难懂；相对于 iptables 而言，该实现就比较难维护了。这就是为了性能而牺牲了可维护性。 所以，有没有类似</description>
    </item>
    <item>
      <title>eBPF Talk: 揭秘 XDP 转发网络包【续】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-25-xdp-redirect-packet/</link>
      <pubDate>Sun, 21 May 2023 16:22:07 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-25-xdp-redirect-packet/</guid>
      <description>书接 eBPF Talk: 揭秘 XDP 转发网络包 未竟的内容，看看最后 generic_xdp_tx() 函数中的发包详情。 1 2 3 4 5 6 // ${KERNEL}/net/core/dev.c generic_xdp_tx() |--&amp;gt;netdev_start_xmit() |--&amp;gt;__netdev_start_xmit() |--&amp;gt;ops-&amp;gt;ndo_start_xmit(skb, dev); 由以上函数调用栈可知，XDP_REDIRECT 和 XDP_TX</description>
    </item>
    <item>
      <title>eBPF Talk: bpf verifier 报告 ENOSPC</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-24-bpf-verifier-enospc/</link>
      <pubDate>Sun, 21 May 2023 16:19:32 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-24-bpf-verifier-enospc/</guid>
      <description>今天遇到个不常见的问题：在往内核装载 bpf 程序时，bpf verifier 报告错误： 1 failed to load bpf with bitmap size 8: failed to load bpf obj and bpf maps: field Acl: program acl: load program: no space left on device: 578: R0=map_value(id=0,off=0,ks=8,vs=64,imm=0) R1_w=map_ptr(id=0,off=0,ks=4,vs=4,imm=0) R2_w=fp-4 R3_w=invP1 R4=invP(id=69 (3524 line(s) omitted) 觉</description>
    </item>
    <item>
      <title>eBPF Talk: 一个 ARRAY bpf map 的使用细节</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-23-a-concrete-usage-of-array-map/</link>
      <pubDate>Sun, 21 May 2023 16:17:25 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-23-a-concrete-usage-of-array-map/</guid>
      <description>创建 bpf map 时，出现了如下错误： 1 failed to load bpf: failed to create map: invalid argument 看下需要创建的 bpf map： 1 2 3 4 5 6 struct { __uint(type, BPF_MAP_TYPE_ARRAY); __type(key, __u8); __type(value, bitmap); __uint(max_entries, PROTO_MAX_ENTRIES); } acl_protocol SEC(&amp;#34;.maps&amp;#34;); 想着，需要处理的 protocol 也就 TCP</description>
    </item>
    <item>
      <title>eBPF Talk: 全局变量实战指南</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-22-global-variables-in-action/</link>
      <pubDate>Sun, 21 May 2023 16:12:19 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-22-global-variables-in-action/</guid>
      <description>类似于常量的使用，如今在 eBPF 里也能够使用全局变量了。 使用例子 源代码：global-variable example 以 kprobe TCP 连接建立事件为例子，当有新的 TCP 连接时</description>
    </item>
    <item>
      <title>eBPF Talk: 优化 XDP ACL</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-21-xdp-acl-optimisation/</link>
      <pubDate>Sun, 21 May 2023 16:08:36 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-21-xdp-acl-optimisation/</guid>
      <description>书接上回 ，本文讲解对高性能 XDP ACL 的开源项目 xdp_acl 的优化内容： 按需开启 eBPF 中的 debug 日志 动态调整 bitmap 大小 使用 PERCPU ARRAY 优化规则 bpf map 动态增删 ACL 规则的处理 以下代码片段</description>
    </item>
    <item>
      <title>eBPF Talk: 再论高性能 eBPF ACL</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-20-xdp-acl-again/</link>
      <pubDate>Sun, 21 May 2023 16:03:32 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-20-xdp-acl-again/</guid>
      <description>因为近期又得搞基于 eBPF 的 ACL，所以再次研究基于 eBPF 的 ACL 的几篇论文和一个开源项目。 以前，我研究过 「eBPF技术实践：高性能ACL」，并实现了一个</description>
    </item>
    <item>
      <title>eBPF Talk: SKB 工作原理【译】</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-19-how-skbs-work/</link>
      <pubDate>Sun, 21 May 2023 16:00:09 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-19-how-skbs-work/</guid>
      <description>翻译自 How SKBs work。 数据区域的布局 第一张图描述的是 SKB 数据区域的布局，以及几个 struct sk_buff 中的指针。 本文余下内容将讲解 SKB 数据区域的操作：通过修改这些指</description>
    </item>
    <item>
      <title>eBPF Talk: bpf helpers 的另一面</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-18-another-side-of-bpf-helpers/</link>
      <pubDate>Sat, 20 May 2023 17:48:25 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-18-another-side-of-bpf-helpers/</guid>
      <description>本文不讲解 bpf helpers 的使用，也不讲解 bpf helpers 的源代码。本文讲解的是，verifier 是怎么处理 bpf helpers 的。 书接上回 eBPF Talk: 揭秘 XDP 转发网络包，本文解答： 为什么 XDP</description>
    </item>
    <item>
      <title>eBPF Talk: 揭秘 XDP 转发网络包</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-17-xdp-redirect-packet/</link>
      <pubDate>Sat, 20 May 2023 17:41:10 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-17-xdp-redirect-packet/</guid>
      <description>书接上回 eBPF Talk: 解密 XDP generic 模式，本文从源代码层面剖析 XDP 转发网络包的实现。 demo 按需将网络包从另一张网卡转发走。 1 2 3 4 5 6 7 8 9 static volatile const u32 REDIRECT_IFINDEX = 0xFFFFFFFF; SEC(&amp;#34;xdp&amp;#34;) int xdp_redirect(struct xdp_md</description>
    </item>
    <item>
      <title>eBPF Talk: 解密 XDP generic 模式</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-16-xdp-generic-mode/</link>
      <pubDate>Sat, 20 May 2023 17:37:39 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-16-xdp-generic-mode/</guid>
      <description>近期又得搞 XDP 了，就顺手研究了下 XDP generic 模式的源代码。 XDP generic 模式的函数位置 已知，内核协议栈会对每个 skb 都执行一次 XDP generic 模式处理，当然是启用了 XDP generic 模式的情</description>
    </item>
    <item>
      <title>eBPF Talk: 好用的 histogram</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-15-useful-histogram/</link>
      <pubDate>Sat, 20 May 2023 17:32:59 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-15-useful-histogram/</guid>
      <description>最近 eBPF 轮子造的多了后，发现需要用 histogram 的时候，要写的代码就一个模板，如下。 以下内容以 syscalldist 为例。 用于 histogram 的 C 代码 参考（抄袭） libbpf-tools 里 histogram 的实现，用于 histogram 的 C 代</description>
    </item>
    <item>
      <title>eBPF Talk: bpf2bpf 特性揭秘</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-14-bpf2bpf-functions-call/</link>
      <pubDate>Sat, 20 May 2023 17:26:45 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-14-bpf2bpf-functions-call/</guid>
      <description>在 eBPF Talk: bpf2bpf 特性简介 中已介绍了 bpf2bpf 特性，同时有 demo 介绍该怎么使用该特性。 在该特性神秘面纱的背后，到底是怎样的呢？让我娓娓道来。 编译阶段 不懂编译器 clang 中</description>
    </item>
    <item>
      <title>eBPF Talk: cilium/ebpf 中 bpf map 的诞生</title>
      <link>https://asphaltt.github.io/post/ebpf-talk-13-bpf-map-new-born-in-cilium_ebpf/</link>
      <pubDate>Sat, 20 May 2023 17:17:39 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-talk-13-bpf-map-new-born-in-cilium_ebpf/</guid>
      <description>在博客 eBPF Talk: 揭秘 BPF map 前生今世，已讲解了 bpf map 从定义到创建的整个过程。 不过博客中讲解的加载器是 C 语言的 libbpf。 在此，就讲解一下纯 Go 语言的加载</description>
    </item>
    <item>
      <title>eBPF Talk: bpf map 源码导读</title>
      <link>https://asphaltt.github.io/post/ebpf-map-source-code-reading-guide/</link>
      <pubDate>Wed, 04 Jan 2023 22:34:51 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-map-source-code-reading-guide/</guid>
      <description>eBPF map 有诸多类型。如果想要理解它们的实现，该如何去阅读它们的源代码呢？ 类型接口 在内核的源代码海洋中，接口的定义一般是：结构体的字段都是函数指针</description>
    </item>
    <item>
      <title>使用 drgn 查看网络设备的私有数据</title>
      <link>https://asphaltt.github.io/post/drgn-netdev_priv/</link>
      <pubDate>Sun, 01 Jan 2023 22:52:56 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/drgn-netdev_priv/</guid>
      <description>这是 drgn 的一个使用例子。 最近在追踪一个 veth 网络设备的问题的时候，发现需要查看 veth 网络设备的 netdev_priv() 获取的私有数据。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19</description>
    </item>
    <item>
      <title>eBPF Talk: syscalldist: raw tracepoint 实战</title>
      <link>https://asphaltt.github.io/post/ebpf-syscalldist/</link>
      <pubDate>Thu, 22 Dec 2022 22:25:37 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-syscalldist/</guid>
      <description>bcc/libbpf-tools 里有许多使用 bcc 实现的小工具。 咱们也来实现一个类似的工具吧。 raw tracepoint 不同于 tracepoint，raw tracepoint 的资料较少。 关于 eBPF 进行 raw tracepoint 的资料更少： bpf,</description>
    </item>
    <item>
      <title>eBPF Talk: 两个简单好用的 map 处理函数</title>
      <link>https://asphaltt.github.io/post/ebpf-two-map-helpers/</link>
      <pubDate>Wed, 21 Dec 2022 21:26:02 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-two-map-helpers/</guid>
      <description>最近在用 eBPF 造轮子的时候，发现其中一个处理函数；而后，自己有样学样地封装了另外一个函数。 bpf_map_lookup_or_try_init 函数名称有点长。 该函数是用来查询某个 key 对应的 valu</description>
    </item>
    <item>
      <title>eBPF Talk: 此汇编非彼汇编</title>
      <link>https://asphaltt.github.io/post/ebpf-asm-and-insn/</link>
      <pubDate>Wed, 21 Dec 2022 21:20:30 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-asm-and-insn/</guid>
      <description>此汇编：在 C 代码里使用的 asm volatile 汇编代码。 彼汇编：eBPF verifier、JIT、runtime VM 等地方使用的汇编指令。 在文章 BPF 尾调用简介 里，</description>
    </item>
    <item>
      <title>eBPF Talk: eBPF 尾调用简介</title>
      <link>https://asphaltt.github.io/post/ebpf-tailcall-intro/</link>
      <pubDate>Thu, 24 Nov 2022 22:11:05 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-tailcall-intro/</guid>
      <description>在 bpf2bpf 特性简介 中提及到 bpf_tail_call()，我们就认真学习一下它吧。 bpf_tail_call 从 4.2 内核版本开始，eBPF 支持了尾调用特性。 该特性的主要特点是</description>
    </item>
    <item>
      <title>eBPF Talk: bpf2bpf 特性简介</title>
      <link>https://asphaltt.github.io/post/ebpf-bpf2bpf-functions-call/</link>
      <pubDate>Wed, 16 Nov 2022 22:32:06 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-bpf2bpf-functions-call/</guid>
      <description>最近才了解到 eBPF 里有 bpf2bpf 这个特性，故特意学习了一番。 bpf2bpf 简介 bpf2bpf 特性要求 4.16 内核版本，参考 BPF Features by Linux Kernel Version。 在 bpf2bpf 特性出现之前，eBPF 程序都要</description>
    </item>
    <item>
      <title>eBPF Talk: BPF map 趣事一则</title>
      <link>https://asphaltt.github.io/post/ebpf-a-bpf-map-story/</link>
      <pubDate>Sun, 13 Nov 2022 21:06:38 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-a-bpf-map-story/</guid>
      <description>有同事报告一个错误：lookup: cannot allocate memory，并请求如何解决。 lookup 项目中使用的 eBPF 库是 cilium/ebpf。查看一下 BPF map lookup 的源代码，如下</description>
    </item>
    <item>
      <title>eBPF Talk: 为当前内核提供外部 BTF 文件</title>
      <link>https://asphaltt.github.io/post/ebpf-external-btf/</link>
      <pubDate>Sun, 06 Nov 2022 21:42:05 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-external-btf/</guid>
      <description>最近系统地学习了 eBPF CO-RE（Compile Once, Run Everywhere，一次编译，到处运行），其中包括了 BTF。 BTF，BPF Type Format，</description>
    </item>
    <item>
      <title>eBPF Talk: 比 kprobe 更好的 trampoline</title>
      <link>https://asphaltt.github.io/post/ebpf-trampoline-better-than-kprobe/</link>
      <pubDate>Tue, 01 Nov 2022 23:31:04 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-trampoline-better-than-kprobe/</guid>
      <description>eBPF trampoline（trampoline：蹦床，翻译后并不好理解，所以不作翻译）是内核函数和 eBPF 程序之间的桥梁，基于 register_ftrace_direct() 实现。它实现了 kprobe/kretprobe 的功</description>
    </item>
    <item>
      <title>eBPF Talk: CPU and NUMA</title>
      <link>https://asphaltt.github.io/post/ebpf-cpu-and-numa/</link>
      <pubDate>Mon, 31 Oct 2022 19:26:29 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-cpu-and-numa/</guid>
      <description>在现代的服务器中，基本上 CPU 采用的都是多核 NUMA 架构。对于网络而言，一个网络包从物理网卡驱动出来之后，并到达对应的应用层 socket，最好都在同一</description>
    </item>
    <item>
      <title>eBPF CO-RE 的终极一步</title>
      <link>https://asphaltt.github.io/post/ebpf-final-step-to-co-re/</link>
      <pubDate>Mon, 31 Oct 2022 19:16:57 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-final-step-to-co-re/</guid>
      <description>请移步：eBPF CO-RE 的终极一步。</description>
    </item>
    <item>
      <title>eBPF Talk: 宏的两种写法</title>
      <link>https://asphaltt.github.io/post/ebpf-two-macros/</link>
      <pubDate>Sun, 30 Oct 2022 15:45:41 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-two-macros/</guid>
      <description>宏是 C 语言中最强大的语言特性，能够用来简化 eBPF 的 C 代码；毕竟 eBPF 的 C 代码是一种语法、语义都受限的 C 代码，不能像普通 C 代码那样“肆意妄为”。 写法一</description>
    </item>
    <item>
      <title>eBPF Talk: 变量声明的位置</title>
      <link>https://asphaltt.github.io/post/ebpf-variables-declaration-location/</link>
      <pubDate>Sat, 29 Oct 2022 15:03:41 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-variables-declaration-location/</guid>
      <description>据了解（未查证），从 clang12 开始，eBPF 代码中的变量声明不再要求写在函数体的最前方，而是可以按需声明并初始化。 写法一：一次性声明全部的变量 1 2 3</description>
    </item>
    <item>
      <title>为 eBPF 程序注入黑魔法 【正确姿势】</title>
      <link>https://asphaltt.github.io/post/ebpf-black-magic-correct/</link>
      <pubDate>Wed, 24 Aug 2022 22:09:42 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-black-magic-correct/</guid>
      <description>为 eBPF 程序注入黑魔法 【错误姿势】 中提出的在加载阶段中动态变更常量值的办法并不可靠，毕竟在 cilium/ebpf 中已提供了重写常量的函数 RewriteConstan</description>
    </item>
    <item>
      <title>为 eBPF 程序注入黑魔法 【错误姿势】</title>
      <link>https://asphaltt.github.io/post/ebpf-black-magic/</link>
      <pubDate>Sat, 11 Jun 2022 14:35:17 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/ebpf-black-magic/</guid>
      <description>在 Kubernetes 集群环境下，如果跨节点的 Pod 需要组成多个 VPC 网络，使用 eBPF 的时候，该如何在 CNI 层面动态地为每个 Pod 分配 VXLAN VNI 或者 VLAN ID 呢？ 一个简单可行的办法是，每次 CNI</description>
    </item>
    <item>
      <title>demo for 「eBPF 技术实践：高性能 ACL」</title>
      <link>https://asphaltt.github.io/post/iptables-bpf-acl/</link>
      <pubDate>Fri, 01 Apr 2022 21:14:32 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/iptables-bpf-acl/</guid>
      <description>在阅读了字节跳动发出的公众号文章 eBPF 技术实践：高性能 ACL 后，对其中提出的 O(1) 匹配算法颇为佩服；但初始看了好几遍，都没看懂这个匹配算法。如今看懂后，</description>
    </item>
    <item>
      <title>一文吃透 Linux nsenter</title>
      <link>https://asphaltt.github.io/post/linux-how-nsenter-works/</link>
      <pubDate>Sat, 22 Jan 2022 14:03:18 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-how-nsenter-works/</guid>
      <description>nsenter 套娃 在 Linux 系统里，nsenter 是一个命令行工具，用于进入到另一个 namespace。譬如，nsenter -n -t 1 bash 就是进入到 pid 为 1 的进程所在</description>
    </item>
    <item>
      <title>一文吃透 Linux TProxy 透明代理</title>
      <link>https://asphaltt.github.io/post/linux-how-tproxy-works/</link>
      <pubDate>Fri, 24 Dec 2021 23:34:52 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-how-tproxy-works/</guid>
      <description>Linux 透明代理并不是一个独立的功能模块，而是一个功能特性。在使用 Linux 透明代理的时候，需要 iptables, ip-rule, ip-route 和应用程序一起协同工作。 Linux 透明代理相关博客： knet</description>
    </item>
    <item>
      <title>在内核模块里运行 bpf 程序</title>
      <link>https://asphaltt.github.io/post/kernel-module-with-bpf/</link>
      <pubDate>Sun, 19 Dec 2021 16:50:09 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/kernel-module-with-bpf/</guid>
      <description>参考 iptables-bpf 的源代码实现，尝试在自定义的内核模块里运行指定的 bpf 程序。 使用的 bpf 程序源代码： iptables-bpf 内核模块源代码：Kernel module fun 效果 1 2 3 4 5 6 7 8 9 10</description>
    </item>
    <item>
      <title>iptables-bpf 的实现原理分析</title>
      <link>https://asphaltt.github.io/post/iptables-bpf-source-code-reading/</link>
      <pubDate>Sun, 19 Dec 2021 14:27:19 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/iptables-bpf-source-code-reading/</guid>
      <description>该如此玩转 iptables-bpf 原始魔杖 iptables 配上新发明的药水 eBPF，这是怎么做到的呢？让我们一探 iptables-bpf 究竟。 实现原理 用法：iptables -I OUTPUT -m bpf --object-pinned $(EBPF_PINNED) -j DROP bpf 是 iptables 的一</description>
    </item>
    <item>
      <title>该如此玩转 iptables-bpf</title>
      <link>https://asphaltt.github.io/post/iptables-bpf/</link>
      <pubDate>Thu, 16 Dec 2021 23:26:45 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/iptables-bpf/</guid>
      <description>在看 iptables-nfqueue 源代码的时候，发现 iptables 有 bpf 特性，于是查了下 iptables-bpf 的资料。 使用iptables的bpf match来优化规则集-HiPAC/ipset/n+1模</description>
    </item>
    <item>
      <title>使用 functrace 排查 Go 函数卡顿问题</title>
      <link>https://asphaltt.github.io/post/go-functrace/</link>
      <pubDate>Wed, 15 Dec 2021 21:07:44 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/go-functrace/</guid>
      <description>在验证 使用 Go 对接 iptables NFQUEUE 的例子 所使用的 go-nfqueue 第三方库 go-nfnetlink 的性能的时候，发现每秒只能处理 4 个网络包，遂使用 functrace 排查了起来。以下记录了排查过程。 排查过程 根据</description>
    </item>
    <item>
      <title>iptables-nfqueue 的使用</title>
      <link>https://asphaltt.github.io/post/iptables-nfqueue-usage/</link>
      <pubDate>Sun, 12 Dec 2021 15:10:20 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/iptables-nfqueue-usage/</guid>
      <description>本文主要翻译自 Using NFQUEUE and libnetfilter_queue，将 C 代码例子换成 Go 代码例子。 介绍 NFQUEUE 是一种 iptables 和 ip6tables 的目标（an iptables and ip6tables target），将</description>
    </item>
    <item>
      <title>一文吃透 iptables-nfqueue</title>
      <link>https://asphaltt.github.io/post/iptables-nfqueue/</link>
      <pubDate>Thu, 09 Dec 2021 23:54:39 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/iptables-nfqueue/</guid>
      <description>iptables 常用，iptables-nfqueue 少用。因需要深度理解 iptables-nfqueue，所以顺手撸了一遍 iptables-nfqueue 的源代码。 iptables-nfqueue ，aka NFQU</description>
    </item>
    <item>
      <title>使用 Go 对接 iptables NFQUEUE 的例子</title>
      <link>https://asphaltt.github.io/post/go-nfnetlink-example/</link>
      <pubDate>Wed, 03 Nov 2021 23:06:24 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/go-nfnetlink-example/</guid>
      <description>最近在学习 iptables NFQUEUE 的时候，顺手使用 Go 语言写了一个例子。 源代码：github.com/Asphaltt/go-nfnetlink-example 例</description>
    </item>
    <item>
      <title>netlink 是 Go 和内核模块之间优秀的通信兵</title>
      <link>https://asphaltt.github.io/post/netlink-and-go/</link>
      <pubDate>Wed, 03 Nov 2021 22:53:38 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/netlink-and-go/</guid>
      <description>netlink 是 Linux 系统里用户态程序、内核模块之间的一种 IPC 方式，特别是用户态程序和内核模块之间的 IPC 通信。比如在 Linux 终端里常用的 ip 命令，就是使用 netlink 去跟内核进行</description>
    </item>
    <item>
      <title>skbtracer: Linux 内核网络包路径追踪利器</title>
      <link>https://asphaltt.github.io/post/skbtracer/</link>
      <pubDate>Tue, 02 Nov 2021 23:19:12 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/skbtracer/</guid>
      <description>skbtracer 是基于 eBPF 技术的 skb 网络包路径追踪利器，基于 goebpf , libbpf-bootstrap (required Linux Kernel 4.15+ with CONFIG_DEBUG_INFO_BTF=y, Go 1.16+) 实现，参考 Python 版本 github.com/DavadDi/skbtracer。 skbtracer</description>
    </item>
    <item>
      <title>Linux 对抗 synflood 的实现</title>
      <link>https://asphaltt.github.io/post/linux-how-anti-synflood-works/</link>
      <pubDate>Wed, 19 May 2021 21:54:30 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-how-anti-synflood-works/</guid>
      <description>synflood 介绍 synflood 是一种 TCP 半连接攻击，会消耗尽服务器资源从而导致服务器拒绝服务。 参考搜狗百科：syn flood。 Linux 中对抗 synflood 的手段 Linux 中对抗 synflood 的主要手段是</description>
    </item>
    <item>
      <title>Linux 自定义 netfilter 钩子实验</title>
      <link>https://asphaltt.github.io/post/linux-custom-netfilter-hook-experiment/</link>
      <pubDate>Mon, 19 Apr 2021 23:48:58 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-custom-netfilter-hook-experiment/</guid>
      <description>学习了 Linux netfilter 钩子执行过程，接下来在内核模块里实现一个自定义的 netfilter 钩子。 netfilter 的网络包处理流程 下图比较详细地描述了 iptables 和 ebtables 的规则执行时机： 图片来源：wi</description>
    </item>
    <item>
      <title>Linux netfilter 钩子执行过程</title>
      <link>https://asphaltt.github.io/post/linux-how-netfilter-works/</link>
      <pubDate>Sun, 18 Apr 2021 12:25:15 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-how-netfilter-works/</guid>
      <description>netfilter 框架是 Linux 网络子系统里的一个核心模块，iptables 就是基于 netfilter 框架实现的一个网络包处理工具。 netfilter 框架原理介绍 在内核里，每个网络命名空间（ne</description>
    </item>
    <item>
      <title>knetstat：查看 socket 的 IP_TRANSPARENT 选项</title>
      <link>https://asphaltt.github.io/post/linux-show-socket-ip_transparent-option/</link>
      <pubDate>Fri, 12 Feb 2021 23:34:58 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-show-socket-ip_transparent-option/</guid>
      <description>在做 Linux 代理流量回放实验 的时候，因为遇到了问题，所以想看下 socket 的 IP_TRANSPARENT 选项是否设置了。该实验使用了 Linux 透明代理的功能，而 Linux 透明代理需要用户程序在使用 socket</description>
    </item>
    <item>
      <title>Linux 策略路由导流到本地</title>
      <link>https://asphaltt.github.io/post/linux-solve-policy-routing-problem/</link>
      <pubDate>Sat, 23 Jan 2021 18:33:40 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-solve-policy-routing-problem/</guid>
      <description>在做 Linux 代理流量回放实验 时，因 ip route 配置失误导致实验失败；排查了一个星期，最终在阅读 Inline on a Linux router 博客时发现了配置失误的地方。 代理流量回放实验 在 namespace server</description>
    </item>
    <item>
      <title>Linux 代理流量回放实验</title>
      <link>https://asphaltt.github.io/post/linux-replay-proxy-traffic-experiment/</link>
      <pubDate>Sat, 23 Jan 2021 17:31:10 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-replay-proxy-traffic-experiment/</guid>
      <description>代理流量回放方案 在 SOCKS5、TCP PROXY、Nginx 等代理中，如若需要对代理的流量还原成真实的 IP 网络包并发给网络审计设备，可以采取如</description>
    </item>
    <item>
      <title>Linux bridge 强制泛洪实验</title>
      <link>https://asphaltt.github.io/post/linux-bridge-flood-experiment/</link>
      <pubDate>Sat, 16 Jan 2021 16:34:24 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-bridge-flood-experiment/</guid>
      <description>在上一章 Linux bridge 泛洪 中介绍了 Linux bridge 强制泛洪的原理，接下来抓一下 bridge 泛洪出来的网络包。 环境准备 学习了 docker网络之namespace 、 docker</description>
    </item>
    <item>
      <title>Linux bridge 泛洪</title>
      <link>https://asphaltt.github.io/post/linux-bridge-flood/</link>
      <pubDate>Wed, 13 Jan 2021 23:39:25 +0800</pubDate>
      <guid>https://asphaltt.github.io/post/linux-bridge-flood/</guid>
      <description>在 Linux 中，bridge 是虚拟的二层网络设备。不同于 eth 或 ens 等真实的网络设备，bridge 能够让同一 Linux 系统内的其他网络设备连接起来；比如 docker 默认的网</description>
    </item>
  </channel>
</rss>
