<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on LeonHuayra&#39;s Blogs</title>
    <link>https://asphaltt.github.io/post/</link>
    <description>Recent content in Posts on LeonHuayra&#39;s Blogs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 19 Dec 2021 16:50:09 +0800</lastBuildDate><atom:link href="https://asphaltt.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>在内核模块里运行 bpf 程序</title>
      <link>https://asphaltt.github.io/post/kernel-module-with-bpf/</link>
      <pubDate>Sun, 19 Dec 2021 16:50:09 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/kernel-module-with-bpf/</guid>
      <description>参考 iptables-bpf 的源代码实现，尝试在自定义的内核模块里运行指定的 bpf 程序。 使用的 bpf 程序参考 iptables-bpf 源代码：Kernel module fun 效果 1 2 3 4 5 6 7 8 9 10 11 12 # make # insmod</description>
    </item>
    
    <item>
      <title>iptables-bpf 的实现原理分析</title>
      <link>https://asphaltt.github.io/post/iptables-bpf-source-code-reading/</link>
      <pubDate>Sun, 19 Dec 2021 14:27:19 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/iptables-bpf-source-code-reading/</guid>
      <description>该如此玩转 iptables-bpf 原始魔杖 iptables 配上新发明的药水 eBPF，这是怎么做到的呢？让我们一探 iptables-bpf 究竟。 实现原理 用法：iptables -I OUTPUT -m bpf --object-pinned $(EBPF_PINNED) -j DROP bpf 是 iptables 的一</description>
    </item>
    
    <item>
      <title>该如此玩转 iptables-bpf</title>
      <link>https://asphaltt.github.io/post/iptables-bpf/</link>
      <pubDate>Thu, 16 Dec 2021 23:26:45 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/iptables-bpf/</guid>
      <description>在看 iptables-nfqueue 源代码的时候，发现 iptables 有 bpf 特性，于是查了下 iptables-bpf 的资料。 使用iptables的bpf match来优化规则集-HiPAC/ipset/n+1模</description>
    </item>
    
    <item>
      <title>使用 functrace 排查 Go 函数卡顿问题</title>
      <link>https://asphaltt.github.io/post/go-functrace/</link>
      <pubDate>Wed, 15 Dec 2021 21:07:44 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/go-functrace/</guid>
      <description>在验证 使用 Go 对接 iptables NFQUEUE 的例子 所使用的 go-nfqueue 第三方库 go-nfnetlink 的性能的时候，发现每秒只能处理 4 个网络包，遂使用 functrace 排查了起来。以下记录了排查过程。 排查过程 根据</description>
    </item>
    
    <item>
      <title>iptables-nfqueue 的使用</title>
      <link>https://asphaltt.github.io/post/iptables-nfqueue-usage/</link>
      <pubDate>Sun, 12 Dec 2021 15:10:20 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/iptables-nfqueue-usage/</guid>
      <description>本文主要翻译自 Using NFQUEUE and libnetfilter_queue，将 C 代码例子换成 Go 代码例子。 介绍 NFQUEUE 是一种 iptables 和 ip6tables 的目标（an iptables and ip6tables target），将</description>
    </item>
    
    <item>
      <title>一文吃透 iptables-nfqueue</title>
      <link>https://asphaltt.github.io/post/iptables-nfqueue/</link>
      <pubDate>Thu, 09 Dec 2021 23:54:39 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/iptables-nfqueue/</guid>
      <description>iptables 常用，iptables-nfqueue 少用。因需要深度理解 iptables-nfqueue，所以顺手撸了一遍 iptables-nfqueue 的源代码。 iptables-nfqueue ，aka NFQU</description>
    </item>
    
    <item>
      <title>使用 Go 对接 iptables NFQUEUE 的例子</title>
      <link>https://asphaltt.github.io/post/go-nfnetlink-example/</link>
      <pubDate>Wed, 03 Nov 2021 23:06:24 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/go-nfnetlink-example/</guid>
      <description>最近在学习 iptables NFQUEUE 的时候，顺手使用 Go 语言写了一个例子。 源代码：github.com/Asphaltt/go-nfnetlink-example 例</description>
    </item>
    
    <item>
      <title>netlink 是 Go 和内核模块之间优秀的通信兵</title>
      <link>https://asphaltt.github.io/post/netlink-and-go/</link>
      <pubDate>Wed, 03 Nov 2021 22:53:38 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/netlink-and-go/</guid>
      <description>netlink 是 Linux 系统里用户态程序、内核模块之间的一种 IPC 方式，特别是用户态程序和内核模块之间的 IPC 通信。比如在 Linux 终端里常用的 ip 命令，就是使用 netlink 去跟内核进行</description>
    </item>
    
    <item>
      <title>skbtracer: Linux 内核网络包路径追踪利器</title>
      <link>https://asphaltt.github.io/post/skbtracer/</link>
      <pubDate>Tue, 02 Nov 2021 23:19:12 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/skbtracer/</guid>
      <description>skbtracer 是基于 eBPF 技术的 skb 网络包路径追踪利器，基于 goebpf , libbpf-bootstrap (required Linux Kernel 4.15+ with CONFIG_DEBUG_INFO_BTF=y, Go 1.16+) 实现，参考 Python 版本 github.com/DavadDi/skbtracer。 skbtracer</description>
    </item>
    
    <item>
      <title>Linux 代理流量回放实验</title>
      <link>https://asphaltt.github.io/post/linux-replay-proxy-traffic-experiment/</link>
      <pubDate>Sat, 23 Jan 2021 17:31:10 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/linux-replay-proxy-traffic-experiment/</guid>
      <description>代理流量回放方案 在 SOCKS5、TCP PROXY、Nginx 等代理中，如若需要对代理的流量还原成真实的 IP 网络包并发给网络审计设备，可以采取如</description>
    </item>
    
    <item>
      <title>Linux bridge 强制泛洪实验</title>
      <link>https://asphaltt.github.io/post/linux-bridge-flood-experiment/</link>
      <pubDate>Sat, 16 Jan 2021 16:34:24 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/linux-bridge-flood-experiment/</guid>
      <description>在上一章 Linux bridge 泛洪 中介绍了 Linux bridge 强制泛洪的原理，接下来抓一下 bridge 泛洪出来的网络包。 环境准备 学习了 docker网络之namespace 、 docker</description>
    </item>
    
    <item>
      <title>Linux bridge 泛洪</title>
      <link>https://asphaltt.github.io/post/linux-bridge-flood/</link>
      <pubDate>Wed, 13 Jan 2021 23:39:25 +0800</pubDate>
      
      <guid>https://asphaltt.github.io/post/linux-bridge-flood/</guid>
      <description>在 Linux 中，bridge 是虚拟的二层网络设备。不同于 eth 或 ens 等真实的网络设备，bridge 能够让同一 Linux 系统内的其他网络设备连接起来；比如 docker 默认的网</description>
    </item>
    
  </channel>
</rss>
